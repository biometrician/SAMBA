---
title: "Statistical Model Building Strategies for Cardiologic Applications - New results and future challenges"
---

**Workshop on the 23th and 24th of November at the Medical University of Vienna**

We cordially invite you to the workshop **Statistical Model Building Strategies for Cardiologic Applications (SAMBA) - New results and future challenges** on November 23th and 24th in Vienna. The workshop is organized by the PIs of the international joint project SAMBA in cooperation with the [Wiener Biometrische Sektion (WBS)](https://www.meduniwien.ac.at/wbs/) and the [Center for Medical Data Science (CeDAS)](https://cemsiis.meduniwien.ac.at/en/) at the [Medical University of Vienna](https://www.meduniwien.ac.at/web/en/). We are delighted to welcome Prof. Dr. **Tobias Pischon** from Berlin, Germany, and Prof. Dr. **Maarten van Smeden** from Utrecht, Netherlands, as keynote speakers. We acknowledge the support by the Austrian Science Funds (FWF) and the Deutsche Forschungsgemeinschaft (DFG) through the joint project SAMBA, grants I4739-B and RA-2347/8-1, respectively.

The workshop will cover two half days. On the afternoon of November 23th our focus will be on the **intersection of epidemiology and biostatistics**. Prof. Pischon will talk on the *Interaction of epidemiology with biostatistics within the large prospective cohort study NAKO with emphasis on cardiovascular diseases* followed by a panel discussion on *Complex longitudinal studies: Needs and challenges in the interaction epidemiology -- biostatistics*. The morning of November 24th is dedicated to **The power and danger of algorithmic model building**, where Prof. van Smeden will give his talk on *Rage against the machine learning*. The participants of the SAMBA project will also present issues and opportunities of statistical model building strategies with a focus on cardiological applications.

The participation in the workshop is free of charge and open to any national and international participants of any scientific discipline interested in the interaction of biostatistics, epidemiology, machine learning and cardiology. 

We are looking forward to welcoming you in Vienna in November!

*Daniela Dunkler, Georg Heinze, Heiko Becher, Geraldine Rauch (organizing committee)*

## Registration

If you intend to come to the workshop, please register here:

[y](https://docs.google.com/forms/d/e/1FAIpQLSfYnvKqiHXADGIJLuwOunU4xh0qoVAzb0s6-UeyskdfKjmL_g/viewform?usp=sf_link)


<iframe src="https://docs.google.com/forms/d/e/1FAIpQLSfYnvKqiHXADGIJLuwOunU4xh0qoVAzb0s6-UeyskdfKjmL_g/viewform?embedded=true" width="640" height="922" frameborder="0" marginheight="0" marginwidth="0">

Loading...

</iframe>

## Programme

### Thursday, 23.11.2023

Topic of the day **Epidemiology and biostatistics: we need each other**

Venue: Medical University Vienna, [Hörsaalzentrum](https://www.meduniwien.ac.at/web/fileadmin/content/serviceeinrichtungen/forschungsservice/international_office/MedUni_Wien_Plan_2016_komplett_1.1.pdf) (building 4 on the attached plan), Hörsaal 3

+---------+---------+----------------------------------------------------------------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------------------------------------+
| Start   | End     | Topic                                                                                                                                                    | Presenter                                                                                                                        |
+=========+=========+==========================================================================================================================================================+==================================================================================================================================+
| 13:00   | 13:05   | Introduction                                                                                                                                             | Daniela Dunkler & Heiko Becher                                                                                                   |
+---------+---------+----------------------------------------------------------------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------------------------------------+
| 13:05   | 13:25   | **Causal model building in the context of cardiac rehabilitation: A systematic review and a case study**                                                 | Daniela Dunkler                                                                                                                  |
+---------+---------+----------------------------------------------------------------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------------------------------------+
| 13:25   | 14:15   | Invited talk: **Interaction of Epidemiology with Biostatistics within the large prospective cohort study NAKO with emphasis on cardiovascular diseases** | Tobias Pischon                                                                                                                   |
+---------+---------+----------------------------------------------------------------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------------------------------------+
| 14:15   | 14:45   | Panel discussion: **Complex longitudinal studies: Needs and challenges in the interaction between biostatistics and epidemiology**                       | Panelists:                                                                                                                       |
|         |         |                                                                                                                                                          |                                                                                                                                  |
|         |         |                                                                                                                                                          | Heiko Becher, Tobias Pischon, Ulrike Grittner, Dörte Huscher, Maarten van Smeden, Geraldine Rauch, Daniela Dunkler, Georg Heinze |
+---------+---------+----------------------------------------------------------------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------------------------------------+
| 14:45   | 15:15   | BREAK                                                                                                                                                    |                                                                                                                                  |
+---------+---------+----------------------------------------------------------------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------------------------------------+
| 15:15   | 15:35   | **Model building using statistical and machine learning approaches: Comparison of performance and explainability**                                       | Christine Schilhart-Wallisch                                                                                                     |
+---------+---------+----------------------------------------------------------------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------------------------------------+
| 15:35   | 15:55   | **Using background knowledge from previous studies in model building: the good, the bad and the ugly**                                                   | Lorena Hafermann                                                                                                                 |
+---------+---------+----------------------------------------------------------------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------------------------------------+
| 15:55   | 16:15   | **Correlated predictors: is variable omission a good default solution?**                                                                                 | Mariella Gregorich                                                                                                               |
+---------+---------+----------------------------------------------------------------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------------------------------------+
| 16:15   | 16:20   | Closing                                                                                                                                                  | Daniela Dunkler                                                                                                                  |
+---------+---------+----------------------------------------------------------------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------------------------------------+

: Programme of day 1

Social programme

### Friday, 24.11.2023

Topic of the day **The power and danger of algorithmic model building**

Venue: Medical University Vienna, [Spitalgasse 23](https://www.google.com/maps/dir//Spitalgasse+23,+1090+Wien/@48.2185593,16.3465908,16.5z/data=!4m8!4m7!1m0!1m5!1m1!1s0x476d07c6c528c823:0x97a73506b8511477!2m2!1d16.3475329!2d48.2196447?entry=ttu), [Jugendstilhörsaal](https://www.meduniwien.ac.at/frauenheilkunde/gyn_data/Jugendstilh%C3%B6rsaal_Wegbeschreibung180416.pdf)

+--------+--------+--------------------------------------------------------------------------------------------------------+--------------------+
| Start  | End    | Topic                                                                                                  | Presenter          |
+========+========+========================================================================================================+====================+
| 9:00   | 9:10   | Introduction                                                                                           | Georg Heinze       |
+--------+--------+--------------------------------------------------------------------------------------------------------+--------------------+
| 9:10   | 9:30   | **Reliable confidence intervals after variable selection: does it work in practice?**                  | Michael Kammer     |
+--------+--------+--------------------------------------------------------------------------------------------------------+--------------------+
| 9:30   | 10:30  | Invited talk: **Rage against the machine learning**                                                    | Maarten van Smeden |
+--------+--------+--------------------------------------------------------------------------------------------------------+--------------------+
| 10:30  | 11:00  | BREAK                                                                                                  |                    |
+--------+--------+--------------------------------------------------------------------------------------------------------+--------------------+
| 11:00  | 11:20  | **Variable selection methods for linear and logistic regression: A comparison of approaches**          | Theresa Ullmann    |
+--------+--------+--------------------------------------------------------------------------------------------------------+--------------------+
| 11:20  | 11:40  | **Variable selection methods for Cox and accelerated failure time models: A comparison of approaches** | Georg Heinze       |
+--------+--------+--------------------------------------------------------------------------------------------------------+--------------------+
| 11:40  | 12:00  | **Variable selection: Improving on the bad habit to ignore selection decisions in model inference**    | Nilufar Akbari     |
+--------+--------+--------------------------------------------------------------------------------------------------------+--------------------+
| 12:00  | 12:05  | Closing                                                                                                | Georg Heinze       |
+--------+--------+--------------------------------------------------------------------------------------------------------+--------------------+

: Programme of day 2

## Abstracts of invited talks

### Interaction of Epidemiology with Biostatistics within the large prospective cohort study NAKO with emphasis on cardiovascular diseases, Tobias Pischon

tba

### Rage against the machine learning, Maarten van Smeden

tba

## Biosketch

### Tobias Pischon

tba

### Maarten van Smeden

Maarten van Smeden is a medical statistician and associate professor at the Julius Center for Health Sciences and Primary Care, UMC Utrecht, the Netherlands. He is coordinating the methodology research program, member of the leadership team of the Julius Center and head of the biostatistics team at the Julius Center. His research is focused on the development and evaluation of statistical methodology, with a particular interest in methodology related to the development and validation of prediction models based on machine learning and artificial intelligence. He is coordinator of the AI methods lab in the UMC Utrecht.

Van Smeden's work has resulted in publications in well-renowned journals in the field of medical statistics (e.g. Statistics in Medicine), epidemiology (e.g. American journal of Epidemiology), and general medicine (e.g. BMJ). As a collaborator, he has also contributed to implementing advanced methodology in a variety of disciplines (e.g. cardiology, infectious diseases, general practice). He is also associate editor at the European Heart Journal, Statistics in Medicine and Diagnostic and Prognostic Research (BMC journals) and has been involved in the development and validation of numerous diagnostic and prognostic prediction models. He is an experienced teacher and invited speaker on topics related to epidemiology, methodology and statistics.

Van Smeden is member and chair of the datasets and communication panels of the [STRATOS initiative](https://www.stratos-initiative.org/), a collaboration of methods experts worldwide who develop guidance on design and analysis of biomedical research. He is the first author on the Dutch guideline for high-quality diagnostic and prognostic applications of AI in healthcare, commissioned by the Dutch Ministry of Health, Welfare and Sport.

## Selected output of the SAMBA project

The project *Statistical Model Building Strategies for Cardiologic Applications* (SAMBA) is funded by the Austrian Science Fund (FWF), grant number I4739-B to Daniela Dunkler, and the Deutsche Forschungsgemeinschaft (DFG), grant number RA-2347/8-1 to Geraldine Rauch and Heiko Becher.

1.  [Gregorich M, Strohmaier S, Dunkler D, Heinze G: Regression with Highly Correlated Predictors: Variable Omission Is Not the Solution. International Journal of Environmental Research and Public Health (2021) 18(8)](https://doi.org/10.3390/ijerph18084259).\
    *Abstract:* Regression models have been in use for decades to explore and quantify the association between a dependent response and several independent variables in environmental sciences, epidemiology and public health. However, researchers often encounter situations in which some independent variables exhibit high bivariate correlation, or may even be collinear. Improper statistical handling of this situation will most certainly generate models of little or no practical use and misleading interpretations. By means of two example studies, we demonstrate how diagnostic tools for collinearity or near-collinearity may fail in guiding the analyst. Instead, the most appropriate way of handling collinearity should be driven by the research question at hand and, in particular, by the distinction between predictive or explanatory aims.

2.  [Hafermann L, Becher H, Herrmann C, Klein N, Heinze G, Rauch G: Statistical Model Building: Background "Knowledge" Based on Inappropriate Preselection Causes Misspecification. BMC Med Res Methodol (2021) 21(1):196](https://doi.org/10.1186/s12874-021-01373-z).\
    *Abstract:*\
    Background: Statistical model building requires selection of variables for a model depending on the model's aim. In descriptive and explanatory models, a common recommendation often met in the literature is to include all variables in the model which are assumed or known to be associated with the outcome independent of their identification with data driven selection procedures. An open question is, how reliable this assumed "background knowledge" truly is. In fact, "known" predictors might be findings from preceding studies which may also have employed inappropriate model building strategies.\
    Methods: We conducted a simulation study assessing the influence of treating variables as "known predictors" in model building when in fact this knowledge resulting from preceding studies might be insufficient. Within randomly generated preceding study data sets, model building with variable selection was conducted. A variable was subsequently considered as a "known" predictor if a predefined number of preceding studies identified it as relevant.\
    Results: Even if several preceding studies identified a variable as a "true" predictor, this classification is often false positive. Moreover, variables not identified might still be truly predictive. This especially holds true if the preceding studies employed inappropriate selection methods such as univariable selection.\
    Conclusions: The source of "background knowledge" should be evaluated with care. Knowledge generated on preceding studies can cause misspecification.

3.  [Wallisch C, Agibetov A, Dunkler D, Haller M, Samwald M, Dorffner G, Heinze G: The Roles of Predictors in Cardiovascular Risk Models - a Question of Modeling Culture? BMC Medical Research Methodology (2021) 21(1):284](https://doi.org/10.1186/s12874-021-01487-4).\
    *Abstract:*\
    Background: While machine learning (ML) algorithms may predict cardiovascular outcomes more accurately than statistical models, their result is usually not representable by a transparent formula. Hence, it is often unclear how specific values of predictors lead to the predictions. We aimed to demonstrate with graphical tools how predictor-risk relations in cardiovascular risk prediction models fitted by ML algorithms and by statistical approaches may differ, and how sample size affects the stability of the estimated relations.\
    Methods: We reanalyzed data from a large registry of 1.5 million participants in a national health screening program. Three data analysts developed analytical strategies to predict cardiovascular events within 1 year from health screening. This was done for the full data set and with gradually reduced sample sizes, and each data analyst followed their favorite modeling approach. Predictor-risk relations were visualized by partial dependence and individual conditional expectation plots.\
    Results: When comparing the modeling algorithms, we found some similarities between these visualizations but also occasional divergence. The smaller the sample size, the more the predictor-risk relation depended on the modeling algorithm used, and also sampling variability played an increased role. Predictive performance was similar if the models were derived on the full data set, whereas smaller sample sizes favored simpler models.\
    Conclusion: Predictor-risk relations from ML models may differ from those obtained by statistical models, even with large sample sizes. Hence, predictors may assume different roles in risk prediction models. As long as sample size is sufficient, predictive accuracy is not largely affected by the choice of algorithm.

4.  [Hafermann L, Klein N, Rauch G, Kammer M, Heinze G: Using Background Knowledge from Preceding Studies for Building a Random Forest Prediction Model: A Plasmode Simulation Study. Entropy (Basel) (2022) 24(6)](https://doi.org/10.3390/e24060847).\
    *Abstract:* There is an increasing interest in machine learning (ML) algorithms for predicting patient outcomes, as these methods are designed to automatically discover complex data patterns. For example, the random forest (RF) algorithm is designed to identify relevant predictor variables out of a large set of candidates. In addition, researchers may also use external information for variable selection to improve model interpretability and variable selection accuracy, thereby prediction quality. However, it is unclear to which extent, if at all, RF and ML methods may benefit from external information. In this paper, we examine the usefulness of external information from prior variable selection studies that used traditional statistical modeling approaches such as the Lasso, or suboptimal methods such as univariate selection. We conducted a plasmode simulation study based on subsampling a data set from a pharmacoepidemiologic study with nearly 200,000 individuals, two binary outcomes and 1152 candidate predictor (mainly sparse binary) variables. When the scope of candidate predictors was reduced based on external knowledge RF models achieved better calibration, that is, better agreement of predictions and observed outcome rates. However, prediction quality measured by cross-entropy, AUROC or the Brier score did not improve. We recommend appraising the methodological quality of studies that serve as an external information source for future prediction model development.

5.  [Kammer M, Dunkler D, Michiels S, Heinze G: Evaluating Methods for Lasso Selective Inference in Biomedical Research: A Comparative Simulation Study. BMC Medical Research Methodology (2022) 22(1):206](https://doi.org/10.1186/s12874-022-01681-y).\
    *Abstract:*\
    Background: Variable selection for regression models plays a key role in the analysis of biomedical data. However, inference after selection is not covered by classical statistical frequentist theory, which assumes a fixed set of covariates in the model. This leads to over-optimistic selection and replicability issues.\
    Methods: We compared proposals for selective inference targeting the submodel parameters of the Lasso and its extension, the adaptive Lasso: sample splitting, selective inference conditional on the Lasso selection (SI), and universally valid post-selection inference (PoSI). We studied the properties of the proposed selective confidence intervals available via R software packages using a neutral simulation study inspired by real data commonly seen in biomedical studies. Furthermore, we present an exemplary application of these methods to a publicly available dataset to discuss their practical usability.\
    Results: Frequentist properties of selective confidence intervals by the SI method were generally acceptable, but the claimed selective coverage levels were not attained in all scenarios, in particular with the adaptive Lasso. The actual coverage of the extremely conservative PoSI method exceeded the nominal levels, and this method also required the greatest computational effort. Sample splitting achieved acceptable actual selective coverage levels, but the method is inefficient and leads to less accurate point estimates. The choice of inference method had a large impact on the resulting interval estimates, thereby necessitating that the user is acutely aware of the goal of inference in order to interpret and communicate the results.\
    Conclusions: Despite violating nominal coverage levels in some scenarios, selective inference conditional on the Lasso selection is our recommended approach for most cases. If simplicity is strongly favoured over efficiency, then sample splitting is an alternative. If only few predictors undergo variable selection (i.e. up to 5) or the avoidance of false positive claims of significance is a concern, then the conservative approach of PoSI may be useful. For the adaptive Lasso, SI should be avoided and only PoSI and sample splitting are recommended. In summary, we find selective inference useful to assess the uncertainties in the importance of individual selected predictors for future applications.

6.  [Akbari N, Heinze G, Rauch G, Sander B, Becher H, Dunkler D: Causal Model Building in the Context of Cardiac Rehabilitation: A Systematic Review. International Journal of Environmental Research and Public Health (2023) 20(4):3182](https://doi.org/10.3390/ijerph20043182).\
    *Abstract:* Randomization is an effective design option to prevent bias from confounding in the evaluation of the causal effect of interventions on outcomes. However, in some cases, randomization is not possible, making subsequent adjustment for confounders essential to obtain valid results. Several methods exist to adjust for confounding, with multivariable modeling being among the most widely used. The main challenge is to determine which variables should be included in the causal model and to specify appropriate functional relations for continuous variables in the model. While the statistical literature gives a variety of recommendations on how to build multivariable regression models in practice, this guidance is often unknown to applied researchers. We set out to investigate the current practice of explanatory regression modeling to control confounding in the field of cardiac rehabilitation, for which mainly non-randomized observational studies are available. In particular, we conducted a systematic methods review to identify and compare statistical methodology with respect to statistical model building in the context of the existing recent systematic review CROS-II, which evaluated the prognostic effect of cardiac rehabilitation. CROS-II identified 28 observational studies, which were published between 2004 and 2018. Our methods review revealed that 24 (86%) of the included studies used methods to adjust for confounding. Of these, 11 (46%) mentioned how the variables were selected and two studies (8%) considered functional forms for continuous variables. The use of background knowledge for variable selection was barely reported and data-driven variable selection methods were applied frequently. We conclude that in the majority of studies, the methods used to develop models to investigate the effect of cardiac rehabilitation on outcomes do not meet common criteria for appropriate statistical model building and that reporting often lacks precision.
